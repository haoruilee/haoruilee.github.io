<!DOCTYPE HTML>
<html>

<head>
	<link rel="bookmark"  type="image/x-icon"  href="/img/logo_miccall.webp"/>
	<link rel="shortcut icon" href="/img/logo_miccall.webp">
	
			    <title>
    Haorui Li
    </title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="/css/mic_main.css" />
    <link rel="stylesheet" href="/css/dropdownMenu.css" />
    <meta name="keywords" content="haoruilee" />
    
    <noscript>
        <link rel="stylesheet" href="/css/noscript.css" />
    </noscript>
    <style type="text/css">
        body:before {
          content: ' ';
          position: fixed;
          top: 0;
          background: url('https://i.dawnlab.me/e6a2105d63e4438f288e4ae4d97f53f2.webp') center 0 no-repeat;
          right: 0;
          bottom: 0;
          left: 0;
          background-size: cover; 
        }
    </style>

			    
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script async type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


    <script src="https://cdnjs.loli.net/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
    <script src="https://cdnjs.loli.net/ajax/libs/jquery.scrollex/0.2.1/jquery.scrollex.min.js"></script>
    <script src="https://cdnjs.loli.net/ajax/libs/skel/3.0.1/skel.min.js"></script>
    <script src="/js/util.js"></script>
    <script src="/js/main.js"></script>
	
<meta name="generator" content="Hexo 7.2.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head>
    
		
<!-- Layouts -->



<!--  代码渲染  -->
<link rel="stylesheet" href="/css/prism_coy.css" />
<link rel="stylesheet" href="/css/typo.css" />
<!-- 文章页 -->
<body class="is-loading">
    <!-- Wrapper 外包 s-->
    <div id="wrapper" class="fade-in">
        <!-- Intro 头部显示 s -->
        <!-- Intro 头部显示 e -->
        <!-- Header 头部logo start -->
        <header id="header">
    <a href="mailto:haoruili@seu.edu.cn" class="logo">Mail Me for offical  or Chat with me for fun</a>
</header>
        <!-- Nav 导航条 start -->
        <nav id="nav" class="special" >
            <ul class="menu links" >
			<!-- Homepage  主页  --> 
			<li >
	            <a href="/" rel="nofollow">Home</a>
	        </li>
			<!-- categories_name  分类   --> 
	        
	        <!-- archives  归档   --> 
	        
	        
		        <!-- Pages 自定义   -->
		        
		        <li>
		            <a href="/life/" title="CV">
		                CV
		            </a>
		        </li>
		        
		        <li>
		            <a href="/tag/" title="Contact">
		                Contact
		            </a>
		        </li>
		        


            </ul>
            <!-- icons 图标   -->
			<ul class="icons">
                    
                    <li>
                        <a title="github" href="https://github.com/haoruilee" target="_blank" rel="noopener">
                            <i class="icon fa fa-github"></i>
                        </a>
                    </li>
                    
			</ul>
</nav>

        <div id="main" >
            <div class ="post_page_title_img" style="height: 25rem;background-image: url(https://i.dawnlab.me/ebe31a362618c5cad62dfadb3866a4e5.png);background-position: center; background-repeat:no-repeat; background-size:cover;-moz-background-size:cover;overflow:hidden;" >
                <a href="#" style="padding: 4rem 4rem 2rem 4rem ;"><h2 >Multi Agent RL &amp; Web3</h2></a>
            </div>
            <!-- Post -->
            <div class="typo" style="padding: 3rem;">
                <h1 id="Multi-Agent-RL-amp-Web3"><a href="#Multi-Agent-RL-amp-Web3" class="headerlink" title="Multi Agent RL &amp; Web3"></a>Multi Agent RL &amp; Web3</h1><p>Recently I read this paper <em>Principal-Agent Reinforcement Learning: Orchestrating AI Agents with Contracts</em> <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.18074">https://arxiv.org/pdf/2407.18074</a> and find it interesting. Not only cuz it trying to solve MARL (Multi-Agent Reinforcement Learning) but also cuz it may comes another point that Agent and Web3 come togther.</p>
<p>Based on this paper’s algo, I proposed this Semi-on-Chain solution struct to solve SSDs (Sequential Social Dilemmas). I havent write the code yet but I may apply it to some Hackathon. If you are interested in this idea, contact me and we can build together!</p>
<h2 id="Introduction-Tackling-Multi-Agent-Chaos"><a href="#Introduction-Tackling-Multi-Agent-Chaos" class="headerlink" title="Introduction: Tackling Multi-Agent Chaos"></a>Introduction: Tackling Multi-Agent Chaos</h2><p>Have you ever had a group project where everyone <strong>wanted</strong> to get a good grade, but half the team was slacking? Or seen traffic turn into a <strong>jam</strong> because no one wanted to let others pass? In these situations, <strong>individual incentives</strong> (like “I don’t want to do extra work” or “I want to be first!”) can clash with the <strong>greater good</strong>.</p>
<p>This tension is typical of <strong>multi-agent systems</strong>. Each agent (or participant) acts for itself, yet there’s a bigger system we care about—like a road network, a shared environment, or even an online collaborative platform.</p>
<p>In <strong>multi-agent reinforcement learning (MARL)</strong>, we try to teach agents how to behave well in a shared environment. But that alone might not guarantee cooperation, especially if agents are purely self-interested. <strong>This is where economics-inspired “contracts” and trustless blockchain execution (Web3) come in.</strong></p>
<hr>
<h2 id="Section-1-Structure-Overview"><a href="#Section-1-Structure-Overview" class="headerlink" title="Section 1: Structure Overview"></a>Section 1: Structure Overview</h2><p>Let’s start with a simple Structure diagram that shows all the pieces—<strong>MARL</strong> (our learning approach), <strong>Q-learning</strong> (the algorithm within MARL), <strong>Contracts</strong> (from economics, for incentives), and <strong>Web3</strong> (blockchain-based execution).</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">     +--------------------------------------------------+</span><br><span class="line">     |            Off-chain RL (Agent &amp; Principal)      |</span><br><span class="line">     |   (MARL with Q-learning &amp; Contract Updates)      |</span><br><span class="line">     +-------------^----------------^--------------------+</span><br><span class="line">                      |                |</span><br><span class="line">                      |                | (Contracts, Rewards)</span><br><span class="line">                      v                |</span><br><span class="line">+----------------------------------------------+</span><br><span class="line">|    Smart Contract on the Blockchain         |</span><br><span class="line">|  (Incentives, Payout Rules, Automated)      |</span><br><span class="line">+----------------------------------------------+</span><br><span class="line">          ^                   |</span><br><span class="line">          |  (Outcome data)   | (Auto payment)</span><br><span class="line">          |                   |</span><br><span class="line">          v                   |</span><br><span class="line">   +-------------------------------+   </span><br><span class="line">   | Multi-Agent Environment (MAE)|</span><br><span class="line">   |  (States, Actions, Rewards)  |</span><br><span class="line">   +-------------------------------+</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>Off-chain RL</strong>: We do the heavy-lifting of training the agents and optimizing the contract offline or in a simulator.  </li>
<li><strong>Smart Contract</strong>: Lives on a blockchain, enforces the final incentive rules automatically (no cheating!).  </li>
<li><strong>Multi-Agent Environment</strong>: Where the actual interactions happen—like a traffic system, a fishery resource, or a game board.</li>
</ul>
<hr>
<h2 id="Section-2-Background"><a href="#Section-2-Background" class="headerlink" title="Section 2: Background"></a>Section 2: Background</h2><h3 id="2-1-Multi-Agent-Reinforcement-Learning-MARL"><a href="#2-1-Multi-Agent-Reinforcement-Learning-MARL" class="headerlink" title="2.1 Multi-Agent Reinforcement Learning (MARL)"></a>2.1 Multi-Agent Reinforcement Learning (MARL)</h3><ul>
<li><p><strong>What is MARL?</strong><br>Think of a group of robots in a factory needing to coordinate. Each robot is an agent. They share the workspace but have local goals (like finishing tasks quickly). MARL helps them learn collectively without a single “boss” controlling them.</p>
</li>
<li><p><strong>Why is it tricky?</strong><br>Agents aren’t just reacting to a static environment. They’re reacting to <strong>each other</strong>. One robot’s path might block another’s route.</p>
</li>
</ul>
<h3 id="2-2-Q-learning-Basics"><a href="#2-2-Q-learning-Basics" class="headerlink" title="2.2 Q-learning Basics"></a>2.2 Q-learning Basics</h3><ul>
<li><p><strong>Definition</strong>:<br>Q-learning is a type of <strong>reinforcement learning</strong> that estimates a “Q-value,” which tells you how good it is to take action $a$ in state $s$, considering future rewards.</p>
</li>
<li><p><strong>Simple example</strong>:<br>Imagine you’re learning to <strong>park your car</strong>. State $s$ might be your position and orientation, action $a$ is turning the wheel left or right, and the reward is how close you get to a perfect park. Over many attempts, you refine your Q-values until you get the hang of it.</p>
</li>
</ul>
<h3 id="2-3-Principal-Agent-Contracts"><a href="#2-3-Principal-Agent-Contracts" class="headerlink" title="2.3 Principal-Agent Contracts"></a>2.3 Principal-Agent Contracts</h3><ul>
<li><p><strong>What is a contract in this context?</strong><br>Suppose your boss can’t see how hard you work; they only observe results—like project success. A <strong>contract</strong> might say: “If the project meets quality X, you get Y bonus.” It incentivizes you to aim for X, even if the effort is hidden.</p>
</li>
<li><p><strong>Why do we need it here?</strong><br>In a multi-agent system, an agent might do actions you can’t monitor directly. So you pay (or punish) them based on an observable <strong>outcome</strong> instead.</p>
</li>
</ul>
<h3 id="2-4-Web3-Blockchain-Smart-Contracts"><a href="#2-4-Web3-Blockchain-Smart-Contracts" class="headerlink" title="2.4 Web3 (Blockchain + Smart Contracts)"></a>2.4 Web3 (Blockchain + Smart Contracts)</h3><ul>
<li><p><strong>Blockchain</strong>:<br>A shared ledger that no single entity fully controls. Like a big spreadsheet, but each row is verified by many people (nodes).</p>
</li>
<li><p><strong>Smart Contracts</strong>:<br>Small pieces of code that automatically run on the blockchain.<br>Example: If you have a distributed ridesharing app, you can store “If passenger confirms arrival, automatically pay the driver 10 tokens” in a smart contract. There’s no single company controlling the transaction—it’s automatically executed once the condition (passenger confirmation) is met.</p>
</li>
</ul>
<hr>
<h2 id="Section-3-How-They-All-Fit-Together"><a href="#Section-3-How-They-All-Fit-Together" class="headerlink" title="Section 3: How They All Fit Together"></a>Section 3: How They All Fit Together</h2><p>The big magic here is that <strong>agents</strong> learn (via Q-learning) in an environment, while a <strong>principal</strong> designs a <strong>contract</strong> to shape their behavior. Finally, <strong>Web3</strong> ensures the agreed-upon payments are actually honored in a trustless manner.</p>
<ol>
<li><p><strong>Agent’s Perspective</strong>:<br>“I want to maximize my total reward, which includes environment rewards (like finishing tasks) <strong>and</strong> any bonus from the contract. So I’ll do Q-learning to figure out which actions yield me the best payoff.”</p>
</li>
<li><p><strong>Principal’s Perspective</strong>:<br>“I can’t force your hidden actions, but I can pay you if you produce outcomes that help the overall system. Let me figure out the minimal payment that still nudges you to do the right thing.”</p>
</li>
<li><p><strong>Blockchain Smart Contract</strong>:<br>“Just give me the rule for how to pay or not pay. When I get verifiable data from an oracle about the outcome, I’ll auto-execute the transaction, so no one can renege.”</p>
</li>
</ol>
<hr>
<h2 id="Section-4-More-Everyday-Examples"><a href="#Section-4-More-Everyday-Examples" class="headerlink" title="Section 4: More Everyday Examples"></a>Section 4: More Everyday Examples</h2><ol>
<li><p><strong>Traffic Coordination Example</strong>  </p>
<ul>
<li>Agents = self-driving cars.  </li>
<li>Principal = city’s traffic authority that wants fewer jams.  </li>
<li>Contract = “If you yield at intersections to keep traffic flowing, you get micro-payments.”  </li>
<li>Web3 = A traffic DAO on a blockchain, so every car’s signals (like yield events) get logged, and the smart contract pays them instantly if the yield event was beneficial.</li>
</ul>
</li>
<li><p><strong>Fisheries Management Example</strong>  </p>
<ul>
<li>Agents = fishing boats.  </li>
<li>Principal = a fishery conservation board.  </li>
<li>Contract = “If you stay within a sustainable catch quota (verified by a satellite or port weigh-in), we pay you a bonus.”  </li>
<li>Web3 = The contract is on a public chain, ensuring no fishery officer can do under-the-table deals or that no boat can claim “we didn’t catch that many fish!” if the satellite/oracle data disagrees.</li>
</ul>
</li>
<li><p><strong>Online Marketplace Example</strong>  </p>
<ul>
<li>Agents = sellers on a platform.  </li>
<li>Principal = platform operator wanting high-quality listings.  </li>
<li>Contract = “If your product rating stays above 4.5 with at least 100 reviews, you get a monthly bonus from the platform.”  </li>
<li>Web3 = The bonus is coded into a smart contract, so you can’t manipulate or skip paying. If oracles confirm your rating is 4.5+, the payout is automatic.</li>
</ul>
</li>
</ol>
<hr>
<h2 id="Section-5-Under-the-Hood-Some-Math"><a href="#Section-5-Under-the-Hood-Some-Math" class="headerlink" title="Section 5: Under the Hood (Some Math)"></a>Section 5: Under the Hood (Some Math)</h2><p>In the paper <em>Principal-Agent Reinforcement Learning: Orchestrating AI Agents with Contracts</em> <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.18074">https://arxiv.org/pdf/2407.18074</a>  you can get clear conductions.</p>
<p><img src="https://i.dawnlab.me/a673fc6bbe7958c69ac4a41c74376412.png" alt="example.png"></p>
<p>Let’s get just a little technical here in this blog:</p>
<h3 id="5-1-Agent’s-Q-function"><a href="#5-1-Agent’s-Q-function" class="headerlink" title="5.1 Agent’s Q-function"></a>5.1 Agent’s Q-function</h3><p>When the principal chooses a “contract policy” $\rho$ (meaning, how it sets payments in each state), the agent’s Q-value looks like this:</p>
<script type="math/tex; mode=display">
Q^*((s,b), a \mid \rho) \;=\; \underbrace{\mathbb{E}_{o \sim \mathcal{O}(s,a)}[b(o)]}_{\text{contract payment}} + \underbrace{\bar{Q}^*(s,a \mid \rho)}_{\text{environment reward}}.</script><ul>
<li>The agent picks $a$ that maximizes both the <strong>immediate payment</strong> from $b(o)$ <strong>plus</strong> the environment-based cumulative reward.</li>
</ul>
<h3 id="5-2-Principal’s-Optimization"><a href="#5-2-Principal’s-Optimization" class="headerlink" title="5.2 Principal’s Optimization"></a>5.2 Principal’s Optimization</h3><p>The principal tries to set contract $b(\cdot)$ so that the agent’s best action in each state aligns with the principal’s goal. Usually, we write something like:</p>
<script type="math/tex; mode=display">
\max_{b \in B}\quad \mathbb{E}\bigl[r^p(s,o) - b(o)\bigr]</script><p>subject to the constraint that the agent’s best response is the “good” action.</p>
<h3 id="5-3-Convergence"><a href="#5-3-Convergence" class="headerlink" title="5.3 Convergence"></a>5.3 Convergence</h3><p>If we keep iterating:</p>
<ol>
<li><strong>Agent</strong> updates its Q-values to respond to the contract.  </li>
<li><strong>Principal</strong> updates the contract once the agent’s new best responses are known.</li>
</ol>
<p>We can often converge to a stable <strong>subgame-perfect equilibrium</strong> (SPE) if the horizon is finite or certain conditions hold.</p>
<hr>
<h2 id="Section-6-Putting-It-together"><a href="#Section-6-Putting-It-together" class="headerlink" title="Section 6: Putting It together"></a>Section 6: Putting It together</h2><ul>
<li><p><strong>Off-chain</strong>:<br>We do big computations (like Q-learning, large neural network updates) offline or in a private server.</p>
</li>
<li><p><strong>On-chain</strong>:<br>We store the final “contract function.” For instance, something that says: “If outcome is $o$, pay agent X tokens.” Payments happen automatically, removing the need for a central admin.</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">+---------------- Off-chain RL (Principal &amp; Agents) ------------------+</span><br><span class="line">|  Principal designs b(o); Agents do Q-learning to find best actions  |</span><br><span class="line">+---------------------+--------------------+--------------------------+</span><br><span class="line">                      |                   |</span><br><span class="line">                      v                   |</span><br><span class="line">              (Publish or update)   (Agent outcome)</span><br><span class="line">                      |                   |</span><br><span class="line">             +--------+--------+      +---+------------------+</span><br><span class="line">             |  Blockchain SC  |&lt;----|        Oracle        |</span><br><span class="line">             |  (stores b(o))  |     |  (verifies outcome)  |</span><br><span class="line">             +-----------------+      +----------------------+</span><br><span class="line">                      |</span><br><span class="line">                      v (if outcome is validated)</span><br><span class="line">                  Automatic Payment</span><br></pre></td></tr></table></figure>

            </div>

            <!-- Post Comments -->
            
    <!-- 使用 DISQUS_CLICK -->
<div id="disqus-comment">
    <div id="disqus_thread"></div>

<!-- add animation -->
<style>
	.disqus_click_btn {
            line-height: 30px;
            margin: 0;
            min-width: 50px;
            padding: 0 14px;
            display: inline-block;
            font-family: "Roboto", "Helvetica", "Arial", sans-serif;
            font-size: 14px;
            font-weight: 400;
            text-transform: uppercase;
            letter-spacing: 0;
            overflow: hidden;
            will-change: box-shadow;
            transition: box-shadow .2s cubic-bezier(.4, 0, 1, 1), background-color .2s cubic-bezier(.4, 0, .2, 1), color .2s cubic-bezier(.4, 0, .2, 1);
            outline: 0;
            cursor: pointer;
            text-decoration: none;
            text-align: center;
            vertical-align: middle;
            border: 0;
            background: rgba(158, 158, 158, .2);
            box-shadow: 0 2px 2px 0 rgba(0, 0, 0, .14), 0 3px 1px -2px rgba(0, 0, 0, .2), 0 1px 5px 0 rgba(0, 0, 0, .12);
            color: #fff;
            background-color: #7EC0EE;
            text-shadow: 0
        }
</style>
	
<div class="btn_click_load" id="disqus_bt"> 
    <button class="disqus_click_btn">点击查看评论</button>
</div>

<!--
<script type="text/javascript">
$('.btn_click_load').click(function() {
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'lee'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    document.getElementById('disqus_bt').style.display = "none";
});
</script>
-->
<script type="text/javascript">
    var disqus_config = function () {
        this.page.url = 'https://li_haor.gitee.io/2025/01/24/MADL_on_chain/';  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = 'https://li_haor.gitee.io/2025/01/24/MADL_on_chain/'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
</script>

<script type="text/javascript">
    $('.btn_click_load').click(function() {  //click to load comments
        (function() { // DON'T EDIT BELOW THIS LINE
            var d = document;
            var s = d.createElement('script');
            s.src = '//lee.disqus.com/embed.js';
            s.setAttribute('data-timestamp', + new Date());
            (d.head || d.body).appendChild(s);
        })();
        $('.btn_click_load').css('display','none');
    });
</script>
</div>
<style>
    #disqus-comment{
        background-color: #eee;
        padding: 2pc;
    }
</style>


        </div>
        <!-- Copyright 版权 start -->
                <div id="copyright">
            <ul>
                <li>&copy;Powered By <a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/" style="border-bottom: none;">hexo</a></li>
                <li>Author  <a target="_blank" rel="noopener" href="https://github.com/haoruilee" style="border-bottom: none;">haoruilee</a></li>
				<li><a target="_blank" rel="noopener" href="https://beian.miit.gov.cn/" style="border-bottom: none;">苏ICP备2020050362号</a></li>
            </ul>
            
				<span id="busuanzi_container_site_pv"> 2025 </span> 
			
        </div>
    </div>
</body>



 	
</html>
