<!DOCTYPE HTML>
<html>

<head>
	<link rel="bookmark"  type="image/x-icon"  href="/img/logo_miccall.webp"/>
	<link rel="shortcut icon" href="/img/logo_miccall.webp">
	
			    <title>
    Haorui Li
    </title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="/css/mic_main.css" />
    <link rel="stylesheet" href="/css/dropdownMenu.css" />
    <meta name="keywords" content="haoruilee" />
    
    <noscript>
        <link rel="stylesheet" href="/css/noscript.css" />
    </noscript>
    <!-- Preload critical images -->
    <link rel="preload" href="https://i.dawnlab.me/e6a2105d63e4438f288e4ae4d97f53f2.webp" as="image">
    <link rel="preload" href="/images/pusheencode.gif" as="image">

    <style type="text/css">
        body:before {
          content: ' ';
          position: fixed;
          top: 0;
          background: url('https://i.dawnlab.me/e6a2105d63e4438f288e4ae4d97f53f2.webp') center 0 no-repeat;
          right: 0;
          bottom: 0;
          left: 0;
          background-size: cover;
        }
    </style>

			    
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script async type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


    <script src="https://cdnjs.loli.net/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
    <script src="https://cdnjs.loli.net/ajax/libs/jquery.scrollex/0.2.1/jquery.scrollex.min.js"></script>
    <script src="https://cdnjs.loli.net/ajax/libs/skel/3.0.1/skel.min.js"></script>
    <script src="/js/util.js"></script>
    <script src="/js/main.js"></script>
	
<meta name="generator" content="Hexo 7.2.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head>
    
		
<!-- Layouts -->



<!--  代码渲染  -->
<link rel="stylesheet" href="/css/prism_coy.css" />
<link rel="stylesheet" href="/css/typo.css" />
<!-- 文章页 -->
<body class="is-loading">
    <!-- Wrapper 外包 s-->
    <div id="wrapper" class="fade-in">
        <!-- Intro 头部显示 s -->
        <!-- Intro 头部显示 e -->
        <!-- Header 头部logo start -->
        <header id="header">
    <a href="mailto:haoruili@seu.edu.cn" class="logo">Mail Me for offical  or Chat with me for fun</a>
</header>
        <!-- Nav 导航条 start -->
        <nav id="nav" class="special" >
            <ul class="menu links" >
			<!-- Homepage  主页  --> 
			<li >
	            <a href="/" rel="nofollow">Home</a>
	        </li>
			<!-- categories_name  分类   --> 
	        
	        <!-- archives  归档   --> 
	        
	        
		        <!-- Pages 自定义   -->
		        
		        <li>
		            <a href="/life/" title="CV">
		                CV
		            </a>
		        </li>
		        
		        <li>
		            <a href="/tag/" title="Contact">
		                Contact
		            </a>
		        </li>
		        


            </ul>
            <!-- icons 图标   -->
			<ul class="icons">
                    
                    <li>
                        <a title="github" href="https://github.com/haoruilee" target="_blank" rel="noopener">
                            <i class="icon fa fa-github"></i>
                        </a>
                    </li>
                    
			</ul>
</nav>

        <div id="main" >
            <div class ="post_page_title_img lazy-bg" data-bg="https://i.dawnlab.me/ebe31a362618c5cad62dfadb3866a4e5.png" style="height: 25rem;background-position: center; background-repeat:no-repeat; background-size:cover;-moz-background-size:cover;overflow:hidden;" >
                <a href="#" style="padding: 4rem 4rem 2rem 4rem ;"><h2 >Multi Agent RL &amp; Web3</h2></a>
            </div>
            <!-- Post -->
            <div class="typo" style="padding: 3rem;">
                <h1 id="multi-agent-rl-web3">Multi Agent RL &amp; Web3</h1>
<p><em>Update at 2025.02.08: I write an implement of this idea <a target="_blank" rel="noopener" href="https://github.com/haoruilee/Principal-Agent-Contract">https://github.com/haoruilee/Principal-Agent-Contract</a></em></p>
<p>Recently I read this paper <em>Principal-Agent Reinforcement Learning: Orchestrating AI Agents with Contracts</em> <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.18074">https://arxiv.org/pdf/2407.18074</a> and find it interesting. Not only cuz it trying to solve MARL (Multi-Agent Reinforcement Learning) but also cuz it may comes another point that Agent and Web3 come togther.</p>
<p>Based on this paper’s algo, I proposed this Semi-on-Chain solution struct to solve SSDs (Sequential Social Dilemmas). I havent write the code yet but I may apply it to some Hackathon. If you are interested in this idea, contact me and we can build together!</p>
<h2 id="introduction-tackling-multi-agent-chaos">Introduction: Tackling Multi-Agent Chaos</h2>
<p>Have you ever had a group project where everyone <strong>wanted</strong> to get a good grade, but half the team was slacking? Or seen traffic turn into a <strong>jam</strong> because no one wanted to let others pass? In these situations, <strong>individual incentives</strong> (like “I don’t want to do extra work” or “I want to be first!”) can clash with the <strong>greater good</strong>.</p>
<p>This tension is typical of <strong>multi-agent systems</strong>. Each agent (or participant) acts for itself, yet there’s a bigger system we care about—like a road network, a shared environment, or even an online collaborative platform.</p>
<p>In <strong>multi-agent reinforcement learning (MARL)</strong>, we try to teach agents how to behave well in a shared environment. But that alone might not guarantee cooperation, especially if agents are purely self-interested. <strong>This is where economics-inspired “contracts” and trustless blockchain execution (Web3) come in.</strong></p>
<hr>
<h2 id="section-1-structure-overview">Section 1: Structure Overview</h2>
<p>Let’s start with a simple Structure diagram that shows all the pieces—<strong>MARL</strong> (our learning approach), <strong>Q-learning</strong> (the algorithm within MARL), <strong>Contracts</strong> (from economics, for incentives), and <strong>Web3</strong> (blockchain-based execution).</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">     +--------------------------------------------------+</span><br><span class="line">     |            Off-chain RL (Agent &amp; Principal)      |</span><br><span class="line">     |   (MARL with Q-learning &amp; Contract Updates)      |</span><br><span class="line">     +-------------^----------------^--------------------+</span><br><span class="line">                      |                |</span><br><span class="line">                      |                | (Contracts, Rewards)</span><br><span class="line">                      v                |</span><br><span class="line">+----------------------------------------------+</span><br><span class="line">|    Smart Contract on the Blockchain         |</span><br><span class="line">|  (Incentives, Payout Rules, Automated)      |</span><br><span class="line">+----------------------------------------------+</span><br><span class="line">          ^                   |</span><br><span class="line">          |  (Outcome data)   | (Auto payment)</span><br><span class="line">          |                   |</span><br><span class="line">          v                   |</span><br><span class="line">   +-------------------------------+   </span><br><span class="line">   | Multi-Agent Environment (MAE)|</span><br><span class="line">   |  (States, Actions, Rewards)  |</span><br><span class="line">   +-------------------------------+</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>Off-chain RL</strong>: We do the heavy-lifting of training the agents and optimizing the contract offline or in a simulator.</li>
<li><strong>Smart Contract</strong>: Lives on a blockchain, enforces the final incentive rules automatically (no cheating!).</li>
<li><strong>Multi-Agent Environment</strong>: Where the actual interactions happen—like a traffic system, a fishery resource, or a game board.</li>
</ul>
<hr>
<h2 id="section-2-background">Section 2: Background</h2>
<h3 id="2-1-multi-agent-reinforcement-learning-marl">2.1 Multi-Agent Reinforcement Learning (MARL)</h3>
<ul>
<li>
<p><strong>What is MARL?</strong><br>
Think of a group of robots in a factory needing to coordinate. Each robot is an agent. They share the workspace but have local goals (like finishing tasks quickly). MARL helps them learn collectively without a single “boss” controlling them.</p>
</li>
<li>
<p><strong>Why is it tricky?</strong><br>
Agents aren’t just reacting to a static environment. They’re reacting to <strong>each other</strong>. One robot’s path might block another’s route.</p>
</li>
</ul>
<h3 id="2-2-q-learning-basics">2.2 Q-learning Basics</h3>
<ul>
<li>
<p><strong>Definition</strong>:<br>
Q-learning is a type of <strong>reinforcement learning</strong> that estimates a “Q-value,” which tells you how good it is to take action <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">a</span></span></span></span> in state <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">s</span></span></span></span>, considering future rewards.</p>
</li>
<li>
<p><strong>Simple example</strong>:<br>
Imagine you’re learning to <strong>park your car</strong>. State <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">s</span></span></span></span> might be your position and orientation, action <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">a</span></span></span></span> is turning the wheel left or right, and the reward is how close you get to a perfect park. Over many attempts, you refine your Q-values until you get the hang of it.</p>
</li>
</ul>
<h3 id="2-3-principal-agent-contracts">2.3 Principal-Agent Contracts</h3>
<ul>
<li>
<p><strong>What is a contract in this context?</strong><br>
Suppose your boss can’t see how hard you work; they only observe results—like project success. A <strong>contract</strong> might say: “If the project meets quality X, you get Y bonus.” It incentivizes you to aim for X, even if the effort is hidden.</p>
</li>
<li>
<p><strong>Why do we need it here?</strong><br>
In a multi-agent system, an agent might do actions you can’t monitor directly. So you pay (or punish) them based on an observable <strong>outcome</strong> instead.</p>
</li>
</ul>
<h3 id="2-4-web3-blockchain-smart-contracts">2.4 Web3 (Blockchain + Smart Contracts)</h3>
<ul>
<li>
<p><strong>Blockchain</strong>:<br>
A shared ledger that no single entity fully controls. Like a big spreadsheet, but each row is verified by many people (nodes).</p>
</li>
<li>
<p><strong>Smart Contracts</strong>:<br>
Small pieces of code that automatically run on the blockchain.<br>
Example: If you have a distributed ridesharing app, you can store “If passenger confirms arrival, automatically pay the driver 10 tokens” in a smart contract. There’s no single company controlling the transaction—it’s automatically executed once the condition (passenger confirmation) is met.</p>
</li>
</ul>
<hr>
<h2 id="section-3-how-they-all-fit-together">Section 3: How They All Fit Together</h2>
<p>The big magic here is that <strong>agents</strong> learn (via Q-learning) in an environment, while a <strong>principal</strong> designs a <strong>contract</strong> to shape their behavior. Finally, <strong>Web3</strong> ensures the agreed-upon payments are actually honored in a trustless manner.</p>
<ol>
<li>
<p><strong>Agent’s Perspective</strong>:<br>
“I want to maximize my total reward, which includes environment rewards (like finishing tasks) <strong>and</strong> any bonus from the contract. So I’ll do Q-learning to figure out which actions yield me the best payoff.”</p>
</li>
<li>
<p><strong>Principal’s Perspective</strong>:<br>
“I can’t force your hidden actions, but I can pay you if you produce outcomes that help the overall system. Let me figure out the minimal payment that still nudges you to do the right thing.”</p>
</li>
<li>
<p><strong>Blockchain Smart Contract</strong>:<br>
“Just give me the rule for how to pay or not pay. When I get verifiable data from an oracle about the outcome, I’ll auto-execute the transaction, so no one can renege.”</p>
</li>
</ol>
<hr>
<h2 id="section-4-more-everyday-examples">Section 4: More Everyday Examples</h2>
<ol>
<li>
<p><strong>Traffic Coordination Example</strong></p>
<ul>
<li>Agents = self-driving cars.</li>
<li>Principal = city’s traffic authority that wants fewer jams.</li>
<li>Contract = “If you yield at intersections to keep traffic flowing, you get micro-payments.”</li>
<li>Web3 = A traffic DAO on a blockchain, so every car’s signals (like yield events) get logged, and the smart contract pays them instantly if the yield event was beneficial.</li>
</ul>
</li>
<li>
<p><strong>Fisheries Management Example</strong></p>
<ul>
<li>Agents = fishing boats.</li>
<li>Principal = a fishery conservation board.</li>
<li>Contract = “If you stay within a sustainable catch quota (verified by a satellite or port weigh-in), we pay you a bonus.”</li>
<li>Web3 = The contract is on a public chain, ensuring no fishery officer can do under-the-table deals or that no boat can claim “we didn’t catch that many fish!” if the satellite/oracle data disagrees.</li>
</ul>
</li>
<li>
<p><strong>Online Marketplace Example</strong></p>
<ul>
<li>Agents = sellers on a platform.</li>
<li>Principal = platform operator wanting high-quality listings.</li>
<li>Contract = “If your product rating stays above 4.5 with at least 100 reviews, you get a monthly bonus from the platform.”</li>
<li>Web3 = The bonus is coded into a smart contract, so you can’t manipulate or skip paying. If oracles confirm your rating is 4.5+, the payout is automatic.</li>
</ul>
</li>
</ol>
<hr>
<h2 id="section-5-under-the-hood-some-math">Section 5: Under the Hood (Some Math)</h2>
<p>In the paper <em>Principal-Agent Reinforcement Learning: Orchestrating AI Agents with Contracts</em> <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2407.18074">https://arxiv.org/pdf/2407.18074</a>  you can get clear conductions.</p>
<p><img src="https://i.dawnlab.me/a673fc6bbe7958c69ac4a41c74376412.png" alt="example.png"></p>
<p>Let’s get just a little technical here in this blog:</p>
<h3 id="5-1-agent-s-q-function">5.1 Agent’s Q-function</h3>
<p>When the principal chooses a “contract policy” <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ρ</mi></mrow><annotation encoding="application/x-tex">\rho</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">ρ</span></span></span></span> (meaning, how it sets payments in each state), the agent’s Q-value looks like this:</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>Q</mi><mo>∗</mo></msup><mo stretchy="false">(</mo><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>a</mi><mo>∣</mo><mi>ρ</mi><mo stretchy="false">)</mo><mtext>  </mtext><mo>=</mo><mtext>  </mtext><munder><munder><mrow><msub><mi mathvariant="double-struck">E</mi><mrow><mi>o</mi><mo>∼</mo><mi mathvariant="script">O</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">[</mo><mi>b</mi><mo stretchy="false">(</mo><mi>o</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><mo stretchy="true">⏟</mo></munder><mtext>contract payment</mtext></munder><mo>+</mo><munder><munder><mrow><msup><mover accent="true"><mi>Q</mi><mo>ˉ</mo></mover><mo>∗</mo></msup><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo>∣</mo><mi>ρ</mi><mo stretchy="false">)</mo></mrow><mo stretchy="true">⏟</mo></munder><mtext>environment reward</mtext></munder><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">Q^*((s,b), a \mid \rho) \;=\; \underbrace{\mathbb{E}_{o \sim \mathcal{O}(s,a)}[b(o)]}_{\text{contract payment}} + \underbrace{\bar{Q}^*(s,a \mid \rho)}_{\text{environment reward}}.
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">ρ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.519864em;vertical-align:-1.7698639999999999em;"></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7500000000000002em;"><span style="top:-1.366244em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">contract payment</span></span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7499999999999999em;"><span class="svg-align" style="top:-1.9968em;"><span class="pstrut" style="height:3em;"></span><span class="stretchy" style="height:0.548em;min-width:1.6em;"><span class="brace-left" style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMinYMin slice'><path d='M0 6l6-6h17c12.688 0 19.313.3 20 1 4 4 7.313 8.3 10 13
 35.313 51.3 80.813 93.8 136.5 127.5 55.688 33.7 117.188 55.8 184.5 66.5.688
 0 2 .3 4 1 18.688 2.7 76 4.3 172 5h399450v120H429l-6-1c-124.688-8-235-61.7
-331-161C60.687 138.7 32.312 99.3 7 54L0 41V6z'/></svg></span><span class="brace-center" style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMidYMin slice'><path d='M199572 214
c100.7 8.3 195.3 44 280 108 55.3 42 101.7 93 139 153l9 14c2.7-4 5.7-8.7 9-14
 53.3-86.7 123.7-153 211-199 66.7-36 137.3-56.3 212-62h199568v120H200432c-178.3
 11.7-311.7 78.3-403 201-6 8-9.7 12-11 12-.7.7-6.7 1-18 1s-17.3-.3-18-1c-1.3 0
-5-4-11-12-44.7-59.3-101.3-106.3-170-141s-145.3-54.3-229-60H0V214z'/></svg></span><span class="brace-right" style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMaxYMin slice'><path d='M399994 0l6 6v35l-6 11c-56 104-135.3 181.3-238 232-57.3
 28.7-117 45-179 50H-300V214h399897c43.3-7 81-15 113-26 100.7-33 179.7-91 237
-174 2.7-5 6-9 10-13 .7-1 7.3-1 20-1h17z'/></svg></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathbb">E</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.02778em;">O</span></span><span class="mopen mtight">(</span><span class="mord mathdefault mtight">s</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">a</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathdefault">b</span><span class="mopen">(</span><span class="mord mathdefault">o</span><span class="mclose">)</span><span class="mclose">]</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.0032em;"><span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.7698639999999999em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.4042179999999997em;vertical-align:-1.584108em;"></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8201099999999997em;"><span style="top:-1.415892em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">environment reward</span></span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8201099999999999em;"><span class="svg-align" style="top:-2.102em;"><span class="pstrut" style="height:3em;"></span><span class="stretchy" style="height:0.548em;min-width:1.6em;"><span class="brace-left" style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMinYMin slice'><path d='M0 6l6-6h17c12.688 0 19.313.3 20 1 4 4 7.313 8.3 10 13
 35.313 51.3 80.813 93.8 136.5 127.5 55.688 33.7 117.188 55.8 184.5 66.5.688
 0 2 .3 4 1 18.688 2.7 76 4.3 172 5h399450v120H429l-6-1c-124.688-8-235-61.7
-331-161C60.687 138.7 32.312 99.3 7 54L0 41V6z'/></svg></span><span class="brace-center" style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMidYMin slice'><path d='M199572 214
c100.7 8.3 195.3 44 280 108 55.3 42 101.7 93 139 153l9 14c2.7-4 5.7-8.7 9-14
 53.3-86.7 123.7-153 211-199 66.7-36 137.3-56.3 212-62h199568v120H200432c-178.3
 11.7-311.7 78.3-403 201-6 8-9.7 12-11 12-.7.7-6.7 1-18 1s-17.3-.3-18-1c-1.3 0
-5-4-11-12-44.7-59.3-101.3-106.3-170-141s-145.3-54.3-229-60H0V214z'/></svg></span><span class="brace-right" style="height:0.548em;"><svg width='400em' height='0.548em' viewBox='0 0 400000 548' preserveAspectRatio='xMaxYMin slice'><path d='M399994 0l6 6v35l-6 11c-56 104-135.3 181.3-238 232-57.3
 28.7-117 45-179 50H-300V214h399897c43.3-7 81-15 113-26 100.7-33 179.7-91 237
-174 2.7-5 6-9 10-13 .7-1 7.3-1 20-1h17z'/></svg></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8201099999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">Q</span></span></span><span style="top:-3.25233em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.16666em;"><span class="mord">ˉ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathdefault">ρ</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.898em;"><span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.584108em;"><span></span></span></span></span></span><span class="mord">.</span></span></span></span></span></p>
<ul>
<li>The agent picks <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">a</span></span></span></span> that maximizes both the <strong>immediate payment</strong> from <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mo stretchy="false">(</mo><mi>o</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">b(o)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">b</span><span class="mopen">(</span><span class="mord mathdefault">o</span><span class="mclose">)</span></span></span></span> <strong>plus</strong> the environment-based cumulative reward.</li>
</ul>
<h3 id="5-2-principal-s-optimization">5.2 Principal’s Optimization</h3>
<p>The principal tries to set contract <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mo stretchy="false">(</mo><mo>⋅</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">b(\cdot)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">b</span><span class="mopen">(</span><span class="mord">⋅</span><span class="mclose">)</span></span></span></span> so that the agent’s best action in each state aligns with the principal’s goal. Usually, we write something like:</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><munder><mo><mi>max</mi><mo>⁡</mo></mo><mrow><mi>b</mi><mo>∈</mo><mi>B</mi></mrow></munder><mspace width="1em"/><mi mathvariant="double-struck">E</mi><mo fence="true">[</mo><msup><mi>r</mi><mi>p</mi></msup><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>o</mi><mo stretchy="false">)</mo><mo>−</mo><mi>b</mi><mo stretchy="false">(</mo><mi>o</mi><mo stretchy="false">)</mo><mo fence="true">]</mo></mrow><annotation encoding="application/x-tex">\max_{b \in B}\quad \mathbb{E}\bigl[r^p(s,o) - b(o)\bigr] 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.6294779999999998em;vertical-align:-0.7794779999999999em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43055999999999994em;"><span style="top:-2.347892em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">b</span><span class="mrel mtight">∈</span><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7794779999999999em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mspace" style="margin-right:1em;"></span><span class="mord"><span class="mord mathbb">E</span></span><span class="mopen"><span class="delimsizing size1">[</span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.714392em;"><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">p</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">o</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.20001em;vertical-align:-0.35001em;"></span><span class="mord mathdefault">b</span><span class="mopen">(</span><span class="mord mathdefault">o</span><span class="mclose">)</span><span class="mclose"><span class="delimsizing size1">]</span></span></span></span></span></span></p>
<p>subject to the constraint that the agent’s best response is the “good” action.</p>
<h3 id="5-3-convergence">5.3 Convergence</h3>
<p>If we keep iterating:</p>
<ol>
<li><strong>Agent</strong> updates its Q-values to respond to the contract.</li>
<li><strong>Principal</strong> updates the contract once the agent’s new best responses are known.</li>
</ol>
<p>We can often converge to a stable <strong>subgame-perfect equilibrium</strong> (SPE) if the horizon is finite or certain conditions hold.</p>
<hr>
<h2 id="section-6-putting-it-together">Section 6: Putting It together</h2>
<ul>
<li>
<p><strong>Off-chain</strong>:<br>
We do big computations (like Q-learning, large neural network updates) offline or in a private server.</p>
</li>
<li>
<p><strong>On-chain</strong>:<br>
We store the final “contract function.” For instance, something that says: “If outcome is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>o</mi></mrow><annotation encoding="application/x-tex">o</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">o</span></span></span></span>, pay agent X tokens.” Payments happen automatically, removing the need for a central admin.</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">+---------------- Off-chain RL (Principal &amp; Agents) ------------------+</span><br><span class="line">|  Principal designs b(o); Agents do Q-learning to find best actions  |</span><br><span class="line">+---------------------+--------------------+--------------------------+</span><br><span class="line">                      |                   |</span><br><span class="line">                      v                   |</span><br><span class="line">              (Publish or update)   (Agent outcome)</span><br><span class="line">                      |                   |</span><br><span class="line">             +--------+--------+      +---+------------------+</span><br><span class="line">             |  Blockchain SC  |&lt;----|        Oracle        |</span><br><span class="line">             |  (stores b(o))  |     |  (verifies outcome)  |</span><br><span class="line">             +-----------------+      +----------------------+</span><br><span class="line">                      |</span><br><span class="line">                      v (if outcome is validated)</span><br><span class="line">                  Automatic Payment</span><br></pre></td></tr></table></figure>

            </div>

            <!-- Post Comments -->
            
    <!-- 使用 DISQUS_CLICK -->
<div id="disqus-comment">
    <div id="disqus_thread"></div>

<!-- add animation -->
<style>
	.disqus_click_btn {
            line-height: 30px;
            margin: 0;
            min-width: 50px;
            padding: 0 14px;
            display: inline-block;
            font-family: "Roboto", "Helvetica", "Arial", sans-serif;
            font-size: 14px;
            font-weight: 400;
            text-transform: uppercase;
            letter-spacing: 0;
            overflow: hidden;
            will-change: box-shadow;
            transition: box-shadow .2s cubic-bezier(.4, 0, 1, 1), background-color .2s cubic-bezier(.4, 0, .2, 1), color .2s cubic-bezier(.4, 0, .2, 1);
            outline: 0;
            cursor: pointer;
            text-decoration: none;
            text-align: center;
            vertical-align: middle;
            border: 0;
            background: rgba(158, 158, 158, .2);
            box-shadow: 0 2px 2px 0 rgba(0, 0, 0, .14), 0 3px 1px -2px rgba(0, 0, 0, .2), 0 1px 5px 0 rgba(0, 0, 0, .12);
            color: #fff;
            background-color: #7EC0EE;
            text-shadow: 0
        }
</style>
	
<div class="btn_click_load" id="disqus_bt"> 
    <button class="disqus_click_btn">点击查看评论</button>
</div>

<!--
<script type="text/javascript">
$('.btn_click_load').click(function() {
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'lee'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    document.getElementById('disqus_bt').style.display = "none";
});
</script>
-->
<script type="text/javascript">
    var disqus_config = function () {
        this.page.url = 'https://li_haor.gitee.io/2025/01/24/MADL_on_chain/';  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = 'https://li_haor.gitee.io/2025/01/24/MADL_on_chain/'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
</script>

<script type="text/javascript">
    $('.btn_click_load').click(function() {  //click to load comments
        (function() { // DON'T EDIT BELOW THIS LINE
            var d = document;
            var s = d.createElement('script');
            s.src = '//lee.disqus.com/embed.js';
            s.setAttribute('data-timestamp', + new Date());
            (d.head || d.body).appendChild(s);
        })();
        $('.btn_click_load').css('display','none');
    });
</script>
</div>
<style>
    #disqus-comment{
        background-color: #eee;
        padding: 2pc;
    }
</style>


        </div>
        <!-- Copyright 版权 start -->
                <div id="copyright">
            <ul>
                <li>&copy;Powered By <a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/" style="border-bottom: none;">hexo</a></li>
                <li>Author  <a target="_blank" rel="noopener" href="https://github.com/haoruilee" style="border-bottom: none;">haoruilee</a></li>
				<li><a target="_blank" rel="noopener" href="https://beian.miit.gov.cn/" style="border-bottom: none;">苏ICP备2020050362号</a></li>
            </ul>
            
				<span id="busuanzi_container_site_pv"> 2025 </span> 
			
        </div>
    </div>
</body>



 	
</html>
