<!DOCTYPE HTML>
<html>

<head>
	<link rel="bookmark"  type="image/x-icon"  href="/img/logo_miccall.webp"/>
	<link rel="shortcut icon" href="/img/logo_miccall.webp">
	
			    <title>
    Haorui Li
    </title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="/css/mic_main.css" />
    <link rel="stylesheet" href="/css/dropdownMenu.css" />
    <meta name="keywords" content="haoruilee" />
    
    <noscript>
        <link rel="stylesheet" href="/css/noscript.css" />
    </noscript>
    <style type="text/css">
        body:before {
          content: ' ';
          position: fixed;
          top: 0;
          background: url('https://i.dawnlab.me/e6a2105d63e4438f288e4ae4d97f53f2.webp') center 0 no-repeat;
          right: 0;
          bottom: 0;
          left: 0;
          background-size: cover; 
        }
    </style>

			    
  


    <script src="https://cdnjs.loli.net/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
    <script src="https://cdnjs.loli.net/ajax/libs/jquery.scrollex/0.2.1/jquery.scrollex.min.js"></script>
    <script src="https://cdnjs.loli.net/ajax/libs/skel/3.0.1/skel.min.js"></script>
    <script src="/js/util.js"></script>
    <script src="/js/main.js"></script>
	
<meta name="generator" content="Hexo 7.2.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head>
    
		
<!-- Layouts -->



<!--  代码渲染  -->
<link rel="stylesheet" href="/css/prism_coy.css" />
<link rel="stylesheet" href="/css/typo.css" />
<!-- 文章页 -->
<body class="is-loading">
    <!-- Wrapper 外包 s-->
    <div id="wrapper" class="fade-in">
        <!-- Intro 头部显示 s -->
        <!-- Intro 头部显示 e -->
        <!-- Header 头部logo start -->
        <header id="header">
    <a href="mailto:haoruili@seu.edu.cn" class="logo">Mail Me for offical  or Chat with me for fun</a>
</header>
        <!-- Nav 导航条 start -->
        <nav id="nav" class="special" >
            <ul class="menu links" >
			<!-- Homepage  主页  --> 
			<li >
	            <a href="/" rel="nofollow">Home</a>
	        </li>
			<!-- categories_name  分类   --> 
	        
	        <!-- archives  归档   --> 
	        
	        
		        <!-- Pages 自定义   -->
		        
		        <li>
		            <a href="/life/" title="CV">
		                CV
		            </a>
		        </li>
		        
		        <li>
		            <a href="/tag/" title="Contact">
		                Contact
		            </a>
		        </li>
		        


            </ul>
            <!-- icons 图标   -->
			<ul class="icons">
                    
                    <li>
                        <a title="github" href="https://github.com/haoruilee" target="_blank" rel="noopener">
                            <i class="icon fa fa-github"></i>
                        </a>
                    </li>
                    
			</ul>
</nav>

        <div id="main" >
            <div class ="post_page_title_img" style="height: 25rem;background-image: url(https://i.dawnlab.me/301d431f599ff7173f78139235e04ffa.md.jpg);background-position: center; background-repeat:no-repeat; background-size:cover;-moz-background-size:cover;overflow:hidden;" >
                <a href="#" style="padding: 4rem 4rem 2rem 4rem ;"><h2 >Qwen QwQ Guid</h2></a>
            </div>
            <!-- Post -->
            <div class="typo" style="padding: 3rem;">
                <h1 id="Qwen-QwQ-for-Solving-Mathematical-Problems-A-Comprehensive-Guide"><a href="#Qwen-QwQ-for-Solving-Mathematical-Problems-A-Comprehensive-Guide" class="headerlink" title="Qwen QwQ for Solving Mathematical Problems: A Comprehensive Guide"></a>Qwen QwQ for Solving Mathematical Problems: A Comprehensive Guide</h1><p>In the rapidly evolving landscape of artificial intelligence, language models have transcended traditional boundaries, enabling applications that were once deemed impossible. Among these, QwQ <a target="_blank" rel="noopener" href="https://qwenlm.github.io/blog/qwq-32b-preview/">https://qwenlm.github.io/blog/qwq-32b-preview/</a> stands out as a formidable tool for tackling complex mathematical problems. In this blog post, we’ll delve into how to effectively utilize QwQ by walking through a detailed example codebase. Whether you’re a data scientist, AI enthusiast, or a Kaggle competitor, this guide will equip you with the knowledge to harness QwQ’s capabilities for mathematical problem-solving.</p>
<p><img src="https://i.dawnlab.me/fcb0be081bc69b3ec33f548edecf7817.png" alt="fcb0be081bc69b3ec33f548edecf7817.png"></p>
<p>This guide is to solve <a target="_blank" rel="noopener" href="https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-2">this kaggle competition</a>. The nodebook is open-sourced <a target="_blank" rel="noopener" href="https://www.kaggle.com/code/itahiro/qwen-qwq-32b-preview-deepreasoning-6a5856">here</a>.</p>
<h2 id="Introduction-to-QwQ"><a href="#Introduction-to-QwQ" class="headerlink" title="Introduction to QwQ"></a>Introduction to QwQ</h2><p><strong>QwQ</strong> is a cutting-edge CoT (Chain-of-Thought)  language model designed to understand and generate human-like text. Leveraging transformer architectures, QwQ excels in various natural language processing tasks, including text generation, translation, summarization, and notably, mathematical problem-solving. Its ability to comprehend complex instructions and perform step-by-step reasoning makes it an invaluable tool for tackling intricate mathematical challenges.</p>
<p>In this guide, we’ll explore how to deploy QwQ to solve mathematical problems by integrating it with Python code execution and serving predictions through an inference server. This comprehensive approach ensures not only accurate answers but also validates the reasoning process behind them.</p>
<h2 id="Understanding-the-Code-Structure"><a href="#Understanding-the-Code-Structure" class="headerlink" title="Understanding the Code Structure"></a>Understanding the Code Structure</h2><p>The provided code is a comprehensive pipeline designed to:</p>
<ol>
<li><p><strong>Load and Configure the QwQ Model:</strong></p>
<ul>
<li>Initialize the language model with specific parameters.</li>
<li>Set up the tokenizer for processing inputs and outputs.</li>
</ul>
</li>
<li><p><strong>Generate and Process Prompts:</strong></p>
<ul>
<li>Use engineered prompts to guide the model’s reasoning process.</li>
<li>Extract Python code from the model’s responses for execution.</li>
</ul>
</li>
<li><p><strong>Execute Python Code:</strong></p>
<ul>
<li>Run the extracted code in a secure, isolated environment.</li>
<li>Capture outputs to verify and refine the model’s answers.</li>
</ul>
</li>
<li><p><strong>Aggregate and Select the Final Answer:</strong></p>
<ul>
<li>Collect answers from multiple reasoning paths.</li>
<li>Use statistical methods to determine the most reliable answer.</li>
</ul>
</li>
</ol>
<p>Let’s break down each component in detail.</p>
<hr>
<h2 id="Loading-and-Configuring-the-QwQ-Model"><a href="#Loading-and-Configuring-the-QwQ-Model" class="headerlink" title="Loading and Configuring the QwQ Model"></a>Loading and Configuring the QwQ Model</h2><h3 id="Model-Path-Configuration"><a href="#Model-Path-Configuration" class="headerlink" title="Model Path Configuration"></a>Model Path Configuration</h3><p>The first step involves specifying the path to the QwQ model. This path points to the location where the model’s weights and configurations are stored.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">llm_model_pth = <span class="string">&#x27;Your_Path/qwen2.5/transformers/qwq-32b-preview-awq/1&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="Initializing-the-Language-Model"><a href="#Initializing-the-Language-Model" class="headerlink" title="Initializing the Language Model"></a>Initializing the Language Model</h3><p>Using the <code>vllm</code> library, we initialize the QwQ model with specific parameters tailored for our use case:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> vllm <span class="keyword">import</span> LLM, SamplingParams</span><br><span class="line"></span><br><span class="line">llm = LLM(</span><br><span class="line">    llm_model_pth,</span><br><span class="line">    max_model_len=<span class="number">32768</span>,              <span class="comment"># Extends context length for long inputs</span></span><br><span class="line">    trust_remote_code=<span class="literal">True</span>,           <span class="comment"># Allows execution of remote code (use with caution)</span></span><br><span class="line">    tensor_parallel_size=<span class="number">4</span>,            <span class="comment"># Utilizes 4 GPUs for parallel processing</span></span><br><span class="line">    gpu_memory_utilization=<span class="number">0.96</span>,       <span class="comment"># Reserves 4% GPU memory for overhead</span></span><br><span class="line">)</span><br><span class="line">tokenizer = llm.get_tokenizer()</span><br></pre></td></tr></table></figure>
<p><strong>Key Parameters:</strong></p>
<ul>
<li><strong><code>max_model_len</code></strong>: Sets an extensive context window, allowing the model to process and generate long sequences.</li>
<li><strong><code>trust_remote_code</code></strong>: Enables the model to execute code from remote repositories. <strong>Caution:</strong> This can pose security risks if the source is untrusted.</li>
<li><strong><code>tensor_parallel_size</code></strong>: Distributes the model across multiple GPUs, enhancing performance for large-scale models.</li>
<li><strong><code>gpu_memory_utilization</code></strong>: Manages GPU memory allocation to prevent overuse.</li>
</ul>
<h2 id="Hyper-Params"><a href="#Hyper-Params" class="headerlink" title="Hyper Params"></a>Hyper Params</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sampling_params = SamplingParams(</span><br><span class="line">    temperature=<span class="number">1.0</span>,</span><br><span class="line">    min_p=<span class="number">0.01</span>,</span><br><span class="line">    skip_special_tokens=<span class="literal">True</span>,</span><br><span class="line">    max_tokens=<span class="number">32768</span>,</span><br><span class="line"></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>Here, min p is from <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2407.01082">this paper</a>.</p>
<p>“min p” is a sampling technique used during text generation to select the next word (or token) in a sequence. It aims to strike a balance between the creativity and coherence of the generated text by setting a minimum probability threshold relative to the most probable word. Let’s delve into the details:</p>
<ol>
<li>Core Concepts:</li>
</ol>
<p>Probability Distribution: When an LLM generates text, it assigns a probability to each word in its vocabulary, representing the likelihood of that word being the next in the sequence. These probabilities form a probability distribution.<br>Most Probable Word (Pmax): Within this distribution, the word with the highest probability is termed the “most probable word,” and its probability is denoted as Pmax.<br>Relative Probability (Pbase): The relative probability of other words is their probability divided by Pmax: Pbase = P(word) / Pmax. This gives you a sense of how likely a word is compared to the most likely option.<br>Scaled Probability (Pscaled): The min p sampling method uses a scaled probability as a selection criterion: Pscaled = min p * Pmax. Only words with a probability greater than or equal to Pscaled are considered for selection.</p>
<ol>
<li>How min p Works:</li>
</ol>
<p>The fundamental idea behind min p is to only consider words whose probability is at least a certain proportion of the “most probable word’s” probability. This proportion is defined by the min p value.</p>
<p>Example: Suppose Pmax is 50%. If min p is set to 0.1, then Pscaled = 0.1 * 50% = 5%. This means only words with a probability of 5% or higher will be considered during the sampling process.</p>
<ol>
<li>The Relationship Between min p and Selected Word Probabilities:</li>
</ol>
<p>Smaller min p Values: A smaller min p value means a smaller Pscaled, allowing more words with lower probabilities to be included in the selection pool. This leads to more diverse and creative text generation but may also reduce the text’s coherence. The model is willing to explore less likely options.<br>Larger min p Values: Conversely, a larger min p value results in a larger Pscaled, meaning only words with probabilities very close to Pmax are considered. This leads to more conservative and coherent text generation but may also make the output monotonous and repetitive. The model sticks closer to the most probable choices.</p>
<ol>
<li>Visual Representation:</li>
</ol>
<p>Imagine a graph where the x-axis represents word probabilities and the y-axis represents the rank of words (sorted by probability from highest to lowest). Different curves on the graph could represent different min p values. The area under each curve would then represent the range of probabilities of words that would be selected. A lower min p value would have a larger area under the curve, signifying a wider range of probabilities being considered.</p>
<p><img src="https://i.dawnlab.me/476edabe66480aeb4079a055ca219981.png" alt="476edabe66480aeb4079a055ca219981.png"></p>
<hr>
<h2 id="Prompt-Engineering-for-Mathematical-Reasoning"><a href="#Prompt-Engineering-for-Mathematical-Reasoning" class="headerlink" title="Prompt Engineering for Mathematical Reasoning"></a>Prompt Engineering for Mathematical Reasoning</h2><p>Effective prompting is crucial for guiding the model’s reasoning process. The code employs a set of carefully crafted prompts designed to elicit step-by-step reasoning and structured answers.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">thoughts = [</span><br><span class="line">    <span class="string">&#x27;Please use chained reasoning to put the answer in \\boxed&#123;&#125;.&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Please reflect and verify while reasoning and put the answer in \\boxed&#123;&#125;.&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Solve the following problem using concise and clear reasoning by placing the answer in \\boxed&#123;&#125;.&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;You are a helpful and reflective maths assistant, please reason step by step to put the answer in \\boxed&#123;&#125;.&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;You are the smartest maths expert in the world, please spike this question and put the answer in \\boxed&#123;&#125;.&#x27;</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p><strong>Purpose of the Prompts:</strong></p>
<ul>
<li><strong>Structured Reasoning</strong>: Directs the model to perform step-by-step reasoning, enhancing the transparency and reliability of its answers.</li>
<li><strong>Answer Formatting</strong>: Instructs the model to encapsulate the final answer within a LaTeX <code>\boxed&#123;&#125;</code> environment, facilitating easy extraction.</li>
</ul>
<h3 id="Generating-the-Next-Prompt"><a href="#Generating-the-Next-Prompt" class="headerlink" title="Generating the Next Prompt"></a>Generating the Next Prompt</h3><p>To introduce variability and prevent the model from falling into repetitive patterns, the <code>make_next_prompt</code> function cycles through the predefined prompts:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">make_next_prompt</span>(<span class="params">text, round_idx</span>):</span><br><span class="line">    default_prompt = thoughts[(round_idx + <span class="number">1</span>) % <span class="built_in">len</span>(thoughts)]</span><br><span class="line">    default_python_code = <span class="string">f&quot;print(&#x27;<span class="subst">&#123;default_prompt&#125;</span>&#x27;)&quot;</span></span><br><span class="line">    <span class="keyword">return</span> default_python_code</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="Extracting-and-Executing-Python-Code"><a href="#Extracting-and-Executing-Python-Code" class="headerlink" title="Extracting and Executing Python Code"></a>Extracting and Executing Python Code</h2><p>One of the innovative aspects of this approach is extracting Python code from the model’s output to verify and compute answers programmatically.</p>
<h3 id="Extracting-Python-Code"><a href="#Extracting-Python-Code" class="headerlink" title="Extracting Python Code"></a>Extracting Python Code</h3><p>The model is expected to embed Python code snippets within markdown code blocks. The following functions parse the model’s response to extract these code snippets:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_python_code</span>(<span class="params">text</span>):</span><br><span class="line">    pattern = <span class="string">r&#x27;```python\s*(.*?)\s*```&#x27;</span></span><br><span class="line">    matches = re.findall(pattern, text, re.DOTALL)</span><br><span class="line">    <span class="keyword">if</span> matches:</span><br><span class="line">        ans = <span class="string">&quot;\n\n&quot;</span>.join(matches)</span><br><span class="line">        <span class="keyword">return</span> ans</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_python_code_list</span>(<span class="params">text</span>):</span><br><span class="line">    pattern = <span class="string">r&#x27;```python\s*(.*?)\s*```&#x27;</span></span><br><span class="line">    ans = []</span><br><span class="line">    matches = re.findall(pattern, text, re.DOTALL)</span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> matches:</span><br><span class="line">        ans.append(m)</span><br><span class="line">    <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<h3 id="Executing-the-Extracted-Code"><a href="#Executing-the-Extracted-Code" class="headerlink" title="Executing the Extracted Code"></a>Executing the Extracted Code</h3><p>To safely execute the extracted Python code, the <code>PythonREPL</code> class is implemented:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> tempfile</span><br><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PythonREPL</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, timeout=<span class="number">8</span></span>):</span><br><span class="line">        self.timeout = timeout</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, query</span>):</span><br><span class="line">        <span class="keyword">with</span> tempfile.TemporaryDirectory() <span class="keyword">as</span> temp_dir:</span><br><span class="line">            temp_file_path = os.path.join(temp_dir, <span class="string">&quot;tmp.py&quot;</span>)</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(temp_file_path, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.write(query)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                result = subprocess.run(</span><br><span class="line">                    [<span class="string">&quot;python3&quot;</span>, temp_file_path],</span><br><span class="line">                    capture_output=<span class="literal">True</span>,</span><br><span class="line">                    check=<span class="literal">False</span>,</span><br><span class="line">                    text=<span class="literal">True</span>,</span><br><span class="line">                    timeout=self.timeout,</span><br><span class="line">                )</span><br><span class="line">            <span class="keyword">except</span> subprocess.TimeoutExpired:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span>, <span class="string">f&quot;Execution timed out after <span class="subst">&#123;self.timeout&#125;</span> seconds.&quot;</span></span><br><span class="line"></span><br><span class="line">            stdout = result.stdout.strip()</span><br><span class="line">            stderr = result.stderr.strip()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> result.returncode == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span>, stdout</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># Clean the error message by removing the temporary file path</span></span><br><span class="line">                error_lines = stderr.split(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">                cleaned_errors = []</span><br><span class="line">                <span class="keyword">for</span> line <span class="keyword">in</span> error_lines:</span><br><span class="line">                    <span class="keyword">if</span> temp_file_path <span class="keyword">in</span> line:</span><br><span class="line">                        line = line.replace(temp_file_path, <span class="string">&quot;&lt;temporary_file&gt;&quot;</span>)</span><br><span class="line">                    cleaned_errors.append(line)</span><br><span class="line">                cleaned_error_msg = <span class="string">&quot;\n&quot;</span>.join(cleaned_errors)</span><br><span class="line">                combined_output = <span class="string">f&quot;<span class="subst">&#123;stdout&#125;</span>\n<span class="subst">&#123;cleaned_error_msg&#125;</span>&quot;</span> <span class="keyword">if</span> stdout <span class="keyword">else</span> cleaned_error_msg</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span>, combined_output</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="Aggregating-and-Selecting-the-Final-Answer"><a href="#Aggregating-and-Selecting-the-Final-Answer" class="headerlink" title="Aggregating and Selecting the Final Answer"></a>Aggregating and Selecting the Final Answer</h2><p>After extracting and executing Python code, the system aggregates the results to determine the most reliable answer.</p>
<h3 id="Extracting-Boxed-Texts"><a href="#Extracting-Boxed-Texts" class="headerlink" title="Extracting Boxed Texts"></a>Extracting Boxed Texts</h3><p>The model’s final answers are expected to be enclosed within <code>\boxed&#123;&#125;</code>. The following function extracts these numerical values:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">extract_boxed_texts</span>(<span class="params">text</span>):</span><br><span class="line">    pattern = <span class="string">r&#x27;\\boxed&#123;(.*?)&#125;&#x27;</span></span><br><span class="line">    matches = re.findall(pattern, text)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> matches:</span><br><span class="line">        <span class="keyword">return</span> []</span><br><span class="line">    ans = []</span><br><span class="line">    <span class="keyword">for</span> content <span class="keyword">in</span> matches:</span><br><span class="line">        <span class="keyword">if</span> content.isdigit():</span><br><span class="line">            num = <span class="built_in">int</span>(content)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            nums = re.findall(<span class="string">r&#x27;\d+&#x27;</span>, content)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> nums:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            num = <span class="built_in">int</span>(nums[-<span class="number">1</span>])</span><br><span class="line">        ans.append(num % <span class="number">1000</span>)</span><br><span class="line">    <span class="keyword">return</span> ans</span><br></pre></td></tr></table></figure>
<h3 id="Selecting-the-Most-Reliable-Answer"><a href="#Selecting-the-Most-Reliable-Answer" class="headerlink" title="Selecting the Most Reliable Answer"></a>Selecting the Most Reliable Answer</h3><p>Given multiple potential answers from various reasoning paths, the <code>select_answer</code> function employs a consensus mechanism:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">select_answer</span>(<span class="params">answers</span>):</span><br><span class="line">    valid_answers = []</span><br><span class="line">    <span class="keyword">for</span> answer <span class="keyword">in</span> answers:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">int</span>(answer) == <span class="built_in">float</span>(answer):</span><br><span class="line">                <span class="keyword">if</span> <span class="number">1</span> &lt; <span class="built_in">int</span>(answer) &lt; <span class="number">999</span> <span class="keyword">and</span> <span class="built_in">int</span>(answer) % <span class="number">100</span> &gt; <span class="number">0</span>:</span><br><span class="line">                    valid_answers.append(<span class="built_in">int</span>(answer))</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> valid_answers:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">49</span>  <span class="comment"># Default fallback answer</span></span><br><span class="line">    _, answer = <span class="built_in">sorted</span>([(v, k) <span class="keyword">for</span> k, v <span class="keyword">in</span> Counter(valid_answers).items()], reverse=<span class="literal">True</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> answer % <span class="number">1000</span></span><br></pre></td></tr></table></figure>
<hr>
<h2 id="Handling-Predictions-and-Responses"><a href="#Handling-Predictions-and-Responses" class="headerlink" title="Handling Predictions and Responses"></a>Handling Predictions and Responses</h2><p>Combine all above together.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter, defaultdict</span><br><span class="line"></span><br><span class="line"><span class="comment"># Global variables for tracking performance</span></span><br><span class="line">g_score = <span class="number">0</span></span><br><span class="line">g_count = <span class="number">0</span></span><br><span class="line">prompt_score = Counter()</span><br><span class="line">answer_contributions = defaultdict(<span class="built_in">list</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict_for_question</span>(<span class="params">question: <span class="built_in">str</span></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">    <span class="keyword">global</span> g_score</span><br><span class="line">    <span class="keyword">global</span> g_count</span><br><span class="line">    <span class="keyword">global</span> prompt_score</span><br><span class="line">    <span class="keyword">global</span> answer_contributions</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Append directive for modulo operation</span></span><br><span class="line">    question += <span class="string">&quot;\nIf the final answer is a number larger than 1000, take modulo 1000. &quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Check for cutoff time or environment variable</span></span><br><span class="line">    <span class="keyword">if</span> time.time() &gt; cutoff_time <span class="keyword">or</span> <span class="keyword">not</span> os.getenv(<span class="string">&#x27;KAGGLE_IS_COMPETITION_RERUN&#x27;</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="number">210</span>  <span class="comment"># Default answer if conditions are not met</span></span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(question)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Initialize multiple message sequences with different prompts</span></span><br><span class="line">    list_of_messages = [</span><br><span class="line">        [</span><br><span class="line">            &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: thoughts[k]&#125;,</span><br><span class="line">            &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: question&#125;</span><br><span class="line">        ] <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>)</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    all_extracted_answers = []</span><br><span class="line">    list_of_idx = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="built_in">len</span>(list_of_messages)))</span><br><span class="line">    max_round = <span class="number">1</span>  <span class="comment"># Can be increased for iterative refinement</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> round_idx <span class="keyword">in</span> <span class="built_in">range</span>(max_round):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;round <span class="subst">&#123;round_idx + <span class="number">1</span>&#125;</span>&quot;</span>)</span><br><span class="line">        list_of_messages = batch_message_generate(list_of_messages)</span><br><span class="line">        extracted_python_answer = batch_message_list_execute_and_get_answer(list_of_messages, round_idx)</span><br><span class="line">        list_of_messages, extracted_answers, list_of_idx  = batch_message_filter(list_of_messages, list_of_idx)</span><br><span class="line">        all_extracted_answers.extend(extracted_python_answer)</span><br><span class="line">        all_extracted_answers.extend(extracted_answers)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;extracted boxed answers:&quot;</span>, extracted_answers)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;extracted python answers:&quot;</span>, extracted_python_answer)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;all extracted answers:&quot;</span>, all_extracted_answers)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> list_of_messages:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    answer = select_answer(all_extracted_answers)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;answer:&quot;</span>, answer)</span><br><span class="line">    correct_answer = get_correct_answer(question)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;correct answer:&quot;</span>, correct_answer)</span><br><span class="line">    g_count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">str</span>(answer) == <span class="built_in">str</span>(correct_answer):</span><br><span class="line">        g_score += <span class="number">1</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;score: <span class="subst">&#123;g_score&#125;</span>/<span class="subst">&#123;g_count&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n\n&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> answer</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="Pros-and-Cons-of-This-Approach"><a href="#Pros-and-Cons-of-This-Approach" class="headerlink" title="Pros and Cons of This Approach"></a>Pros and Cons of This Approach</h2><h3 id="Pros"><a href="#Pros" class="headerlink" title="Pros"></a>Pros</h3><ol>
<li><strong>Comprehensive Pipeline</strong>: The code covers the entire workflow from model loading to serving predictions, providing an end-to-end solution.</li>
<li><strong>Structured Reasoning</strong>: Using engineered prompts and executing Python code ensures that the model’s reasoning is transparent and verifiable.</li>
<li><strong>Scalability</strong>: Leveraging tensor parallelism and GPU optimization allows handling large models and high-throughput predictions.</li>
<li><strong>Automated Verification</strong>: Executing extracted code provides a mechanism to validate and refine the model’s answers programmatically.</li>
<li><strong>Integration with Kaggle</strong>: Tailored for Kaggle competitions, the code seamlessly fits into competitive environments, enhancing its practical utility.</li>
</ol>
<h3 id="Cons"><a href="#Cons" class="headerlink" title="Cons"></a>Cons</h3><ol>
<li><strong>Security Risks</strong>: Executing code extracted from model outputs poses significant security threats, even within temporary directories and with timeouts.</li>
<li><strong>Dependence on Formatting</strong>: The extraction functions rely heavily on the model’s adherence to specific output formats (e.g., <code>\boxed&#123;&#125;</code>), which may not always hold. (In fact, in my test cases there’s high potential it wont follow the format instruction.)</li>
</ol>
<hr>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Harnessing the capabilities of QwQ for solving mathematical problems offers a powerful blend of natural language understanding and computational verification. By integrating structured prompting, Python code execution, and an efficient inference server, this approach ensures both accuracy and reliability in the answers generated.</p>

            </div>

            <!-- Post Comments -->
            
    <!-- 使用 DISQUS_CLICK -->
<div id="disqus-comment">
    <div id="disqus_thread"></div>

<!-- add animation -->
<style>
	.disqus_click_btn {
            line-height: 30px;
            margin: 0;
            min-width: 50px;
            padding: 0 14px;
            display: inline-block;
            font-family: "Roboto", "Helvetica", "Arial", sans-serif;
            font-size: 14px;
            font-weight: 400;
            text-transform: uppercase;
            letter-spacing: 0;
            overflow: hidden;
            will-change: box-shadow;
            transition: box-shadow .2s cubic-bezier(.4, 0, 1, 1), background-color .2s cubic-bezier(.4, 0, .2, 1), color .2s cubic-bezier(.4, 0, .2, 1);
            outline: 0;
            cursor: pointer;
            text-decoration: none;
            text-align: center;
            vertical-align: middle;
            border: 0;
            background: rgba(158, 158, 158, .2);
            box-shadow: 0 2px 2px 0 rgba(0, 0, 0, .14), 0 3px 1px -2px rgba(0, 0, 0, .2), 0 1px 5px 0 rgba(0, 0, 0, .12);
            color: #fff;
            background-color: #7EC0EE;
            text-shadow: 0
        }
</style>
	
<div class="btn_click_load" id="disqus_bt"> 
    <button class="disqus_click_btn">点击查看评论</button>
</div>

<!--
<script type="text/javascript">
$('.btn_click_load').click(function() {
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'lee'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    document.getElementById('disqus_bt').style.display = "none";
});
</script>
-->
<script type="text/javascript">
    var disqus_config = function () {
        this.page.url = 'https://li_haor.gitee.io/2024/12/23/Qwn_QwQ_for_Math/';  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = 'https://li_haor.gitee.io/2024/12/23/Qwn_QwQ_for_Math/'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
</script>

<script type="text/javascript">
    $('.btn_click_load').click(function() {  //click to load comments
        (function() { // DON'T EDIT BELOW THIS LINE
            var d = document;
            var s = d.createElement('script');
            s.src = '//lee.disqus.com/embed.js';
            s.setAttribute('data-timestamp', + new Date());
            (d.head || d.body).appendChild(s);
        })();
        $('.btn_click_load').css('display','none');
    });
</script>
</div>
<style>
    #disqus-comment{
        background-color: #eee;
        padding: 2pc;
    }
</style>


        </div>
        <!-- Copyright 版权 start -->
                <div id="copyright">
            <ul>
                <li>&copy;Powered By <a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/" style="border-bottom: none;">hexo</a></li>
                <li>Author  <a target="_blank" rel="noopener" href="https://github.com/haoruilee" style="border-bottom: none;">haoruilee</a></li>
				<li><a target="_blank" rel="noopener" href="https://beian.miit.gov.cn/" style="border-bottom: none;">苏ICP备2020050362号</a></li>
            </ul>
            
				<span id="busuanzi_container_site_pv"> 2025 </span> 
			
        </div>
    </div>
</body>



 	
</html>
